{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 162,
         "id": "f8c5f2b3-b89b-4d6a-b06c-281150e860ce",
         "metadata": {},
         "outputs": [],
         "source": [
            "from pytorch_lightning import LightningModule\n",
            "import wandb\n",
            "from pytorch_lightning.loggers import WandbLogger\n",
            "from abc import abstractmethod  \n",
            "from collections import OrderedDict\n",
            "\n",
            "class MLP(nn.Module):\n",
            "    def __init__(self, in_size, n_classes):\n",
            "        super().__init__()\n",
            "        self.model = nn.Sequential(\n",
            "            nn.Flatten(),\n",
            "            nn.Linear(in_size, in_size // 2),\n",
            "            nn.ReLU(),\n",
            "            nn.Linear(in_size // 2, in_size // 4),\n",
            "            nn.ReLU(),\n",
            "            nn.Linear(in_size // 4, n_classes)\n",
            "        )\n",
            "        \n",
            "    def forward(self, x):\n",
            "        return F.log_softmax(self.model(x), dim=1)\n",
            "    \n",
            "    \n",
            "class DeepCNN(nn.Module):\n",
            "    def __init__(self, in_channels, in_dim, n_classes):\n",
            "        super().__init__()\n",
            "        cnn_flat_out_dim = int(in_dim * in_dim * 3 / 4)\n",
            "        self.model = nn.Sequential(OrderedDict([\n",
            "            # [3, in_dim, in_dim]\n",
            "            ('cnn_block_1', self.get_cnn_block(in_channels,    out_channels=6,  kernel_size=3, padding=1)),   # [6,  in_dim / 2, in_dim / 2]\n",
            "            ('cnn_block_2', self.get_cnn_block(in_channels=6,  out_channels=12, kernel_size=3, padding=1)),   # [12, in_dim / 4, in_dim / 4]\n",
            "            ('flatten', nn.Flatten()),                                                                        # 12 * in_dim / 4 * in_dim / 4 = in_dim * in_dim * 3 / 4\n",
            "            ('linear_1', nn.Linear(cnn_flat_out_dim, cnn_flat_out_dim // 2)),                                 # in_dim * in_dim * 3 / 8 \n",
            "            ('relu', nn.ReLU()),                                                                              # in_dim * in_dim * 3 / 8 \n",
            "            ('linear_2', nn.Linear(cnn_flat_out_dim // 2, n_classes))                                         # n_classes\n",
            "        ]))\n",
            "        \n",
            "    def get_cnn_block(self, in_channels, out_channels, kernel_size, padding):\n",
            "        return nn.Sequential(\n",
            "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding),\n",
            "            nn.ReLU(),\n",
            "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
            "        )\n",
            "        \n",
            "    def forward(self, x):\n",
            "        return F.log_softmax(self.model(x), dim=1)\n",
            "\n",
            "    \n",
            "    \n",
            "class ImagePredictionLogger(pl.Callback):\n",
            "    def __init__(self, val_samples, num_samples=32):\n",
            "        super().__init__()\n",
            "        self.val_imgs, self.val_labels = val_samples\n",
            "        self.val_imgs = self.val_imgs[:num_samples]\n",
            "        self.val_labels = self.val_labels[:num_samples]\n",
            "          \n",
            "    def on_validation_epoch_end(self, trainer, pl_module):\n",
            "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
            "\n",
            "        preds = pl_module(val_imgs).argmax(axis=1)\n",
            "        trainer.logger.experiment.log({\n",
            "            \"examples\": [wandb.Image(x, caption=f\"Pred:{pred}, Label:{y}\") \n",
            "                            for x, pred, y in zip(val_imgs, preds, self.val_labels)],\n",
            "            \"global_step\": trainer.global_step\n",
            "            })\n",
            "        \n",
            "        \n",
            "class FeatureActivationsLogger(pl.Callback):\n",
            "    def __init__(self, val_samples, num_samples=4):\n",
            "        super().__init__()\n",
            "        self.val_imgs, self.val_labels = val_samples\n",
            "        self.val_imgs = self.val_imgs[:num_samples]\n",
            "        self.val_labels = self.val_labels[:num_samples]\n",
            "          \n",
            "    def on_validation_epoch_end(self, trainer, pl_module):\n",
            "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
            "        imgage_classifier = trainer.model\n",
            "        cnn_layer = image_classifier.classifier.model.cnn_block_1[0]\n",
            "        kernels = cnn_layer._parameters['weight']\n",
            "        kenerls_min, kernels_max = kernels.min(), kernels.max()        \n",
            "        n_samples = len(val_imgs)\n",
            "        n_channels = len(kernels)\n",
            "        fig, axes = plt.subplots(n_samples + 1, n_channels + 1, figsize=(20, 10))\n",
            "        axes[0, 0].axis('off')\n",
            "        axes[0, 1].set_ylabel(\"Kernels\", fontsize=16, fontweight='bold')\n",
            "        axes[1, 0].set_title(\"Input to Conv\", fontsize=16, fontweight='bold')\n",
            "        for filt_idx, ax in enumerate(axes[0, 1:]):\n",
            "            ax.imshow(kernels[filt_idx].squeeze().cpu(), cmap='gray', vmin=kenerls_min, vmax=kernels_max)\n",
            "        for x, ax in zip(val_imgs, axes[1:, 0]):\n",
            "            ax.imshow(x.cpu().numpy().transpose(1, 2, 0), cmap='gray')\n",
            "\n",
            "        for sample_idx, x in enumerate(val_imgs):\n",
            "            for filt_idx in range(n_channels):\n",
            "                ax = axes[sample_idx + 1, filt_idx + 1]\n",
            "                out_min, out_max = cnn_layer(x).min(), cnn_layer(x).max()\n",
            "                ax.imshow(cnn_layer(x)[filt_idx].cpu(), cmap='gray', vmin=out_min, vmax=out_max)\n",
            "        for ax in axes.flatten():\n",
            "            ax.tick_params(axis='both', which='both', left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
            "        plt.tight_layout()\n",
            "        trainer.logger.experiment.log({'feature_activations': fig, \"global_step\": trainer.global_step})\n",
            "        plt.close()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 173,
         "id": "96d87b53-599d-45d9-935f-f6c34a70448c",
         "metadata": {
            "collapsed": true,
            "jupyter": {
               "outputs_hidden": true
            },
            "tags": []
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href=\"https://wandb.me/wandb-init\" target=\"_blank\">the W&B docs</a>."
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "wandb version 0.12.19 is available!  To upgrade, please run:\n",
                     " $ pip install wandb --upgrade"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Tracking run with wandb version 0.12.18"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Run data is saved locally in <code>/home/shate/Desktop/website/cnn-image-classification/wandb/run-20220623_092517-1pfz2y55</code>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Syncing run <strong><a href=\"https://wandb.ai/thawro/lit-wandb/runs/1pfz2y55\" target=\"_blank\">quiet-meadow-23</a></strong> to <a href=\"https://wandb.ai/thawro/lit-wandb\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "GPU available: True, used: True\n",
                  "TPU available: False, using: 0 TPU cores\n",
                  "IPU available: False, using: 0 IPUs\n",
                  "HPU available: False, using: 0 HPUs\n"
               ]
            },
            {
               "ename": "RuntimeError",
               "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1217\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:71\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msetup(trainer)\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:68\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/core/mixins/device_dtype_mixin.py:121\u001b[0m, in \u001b[0;36mDeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__update_properties(device\u001b[38;5;241m=\u001b[39mout[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mout[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
                  "    \u001b[0;31m[... skipping similar frames: Module._apply at line 578 (1 times)]\u001b[0m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
                  "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
                  "\nDuring handling of the above exception, another exception occurred:\n",
                  "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                  "Input \u001b[0;32mIn [173]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m WandbLogger(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlit-wandb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     28\u001b[0m     logger\u001b[38;5;241m=\u001b[39mwandb_logger,\n\u001b[1;32m     29\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:738\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mreconciliate_processes(traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exception)\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1300\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\u001b[39;00m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;124;03mCallback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_dispatch(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1300\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:98\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# clean up memory\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/memory.py:114\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                  "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
               ]
            }
         ],
         "source": [
            "wandb.login()\n",
            "\n",
            "# mnist = MNISTDataModule()\n",
            "data = mnist\n",
            "test_sample = next(iter(data.test_dataloader()))\n",
            "input_shape = test_sample[0][0].shape\n",
            "input_size = input_shape.numel()\n",
            "in_channels = input_shape[0]\n",
            "in_dim = input_shape[1]\n",
            "n_classes = len(data.val_dataloader().dataset.dataset.classes)\n",
            "\n",
            "# model\n",
            "# classifier = MLP(input_size=input_size, n_classes=n_classes)\n",
            "classifier = DeepCNN(in_channels=in_channels, in_dim=in_dim, n_classes=n_classes)\n",
            "\n",
            "\n",
            "image_classifier = ImageClassifier(in_dims=input_shape, classifier=classifier)\n",
            "\n",
            "callbacks = [\n",
            "    pl.callbacks.EarlyStopping('val/loss', patience=5),\n",
            "    ImagePredictionLogger(test_sample),\n",
            "    FeatureActivationsLogger(test_sample)\n",
            "]\n",
            "wandb_logger = WandbLogger(project=\"lit-wandb\")\n",
            "\n",
            "\n",
            "trainer = pl.Trainer(\n",
            "    logger=wandb_logger,\n",
            "    accelerator='gpu',\n",
            "    callbacks=callbacks,\n",
            "    # profiler=\"simple\",\n",
            "    max_epochs=2\n",
            ")\n",
            "\n",
            "trainer.fit(image_classifier, data)\n",
            "\n",
            "wandb.finish()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "274b8895-57ed-467e-96fc-63d3cf37e5dd",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "Python 3 (ipykernel)",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.2"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}